{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict_mrcnn\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 18, 33, 48, 63, 78, 93])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3, 100, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = io.imread(\"/Volumes/MyPassport1/D1/depth/4973AM/_Depth_1279.png\")\n",
    "# image = cv2.imread(\"/Users/yebi/Library/CloudStorage/OneDrive-VirginiaTech/Research/Codes/research/BCS/BodyWeight/MaskRCNN/images/dataset/pic_test/4973PM_Depth_60848.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_img = predict_mrcnn.predict_mrcnn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(fill_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts, _ = cv2.findContours(fill_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) \n",
    "    # print(f\"There are {len(cnts)} countorus (shapes) in total \\n\")\n",
    "cmax = max(cnts, key=cv2.contourArea) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rect = cv2.minAreaRect(cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box=cv2.boxPoints(rect)\n",
    "box = np.int0(box) #transfer into integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_img = cv2.cvtColor(fill_img, cv2.COLOR_GRAY2RGB) \n",
    "nts_img_bi=cv2.drawContours(rgb_img.copy(), [cmax], 0, (255,0,255), 3)\n",
    "area_img = cv2.drawContours(nts_img_bi.copy(), [box], 0, (0, 255, 0), 3)\n",
    "# cv2.imshow(\"test\", area_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(area_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = cv2.moments(cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_centroid = int(M[\"m01\"] / M[\"m00\"])\n",
    "col_centroid  = int(M[\"m10\"] / M[\"m00\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_centroid, col_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/Volumes/MyPassport1/D1/depth/5145PM/_Depth_20252.png\"\n",
    "img = io.imread(file_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('/Users/yebi/Library/CloudStorage/OneDrive-VirginiaTech/Research/Codes/research/BCS/BodyWeight') \n",
    "\n",
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description = 'Extracting image descriptors from image')\n",
    "# parser.add_argument('day', help = 'day info.')\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "\n",
    "import sys\n",
    "from scipy import stats # summarize data\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from scipy.spatial import distance as dist\n",
    "# from imutils import perspective\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import predict_mrcnn\n",
    "import skimage.io as io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rootdir = \"./DairyLMC\"\n",
    "rootdir = \"/Volumes/MyPassport1\"\n",
    "# depthdir = \"./DairyLMC/D1/depth/4973AM\"\n",
    "temp_dep = \"/Volumes/MyPassport1/\" + \"D1\" + \"/depth/\"\n",
    "temp_csv = \"/Volumes/MyPassport1/\" + \"D1\" + \"/CSV/\"\n",
    "# csvdir = \"./DairyLMC/D1/CSV/4973AM/\"\n",
    "temp_day = \"/Users/yebi/Library/CloudStorage/OneDrive-VirginiaTech/Research/Codes/research/BCS/BodyWeight/outputs/mrcnn/\" + \"D1\" + \"/\" + \"D1\" + \"_\"\n",
    "i = 1\n",
    "\n",
    "for cowid in os.listdir(temp_dep):\n",
    "      summ = os.path.join(temp_day+cowid+\".csv\")\n",
    "  # if os.path.isfile(summ):\n",
    "  #   print(\"already there, go to next one\")\n",
    "  #   continue\n",
    "  # else:\n",
    "      depthdir = temp_dep + cowid + \"/\"\n",
    "      csvdir = temp_csv + cowid + \"/\"\n",
    "      with open(summ, \"w\", newline = \"\") as output:\n",
    "          writer = csv.writer(output)\n",
    "          writer.writerow([\"Day\", \"ID\", \"Frame\", \"Width\", \"Length\", \"Height_Centroid\", \"Height_average\", \"Volume\"])\n",
    "          for root, dirs, files in os.walk(depthdir):\n",
    "            Day = root.split(\"/\")[3]\n",
    "            ID = root.split(\"/\")[5]\n",
    "\n",
    "            for j in np.arange(3, len(files), 15):\n",
    "                file = files[j]\n",
    "                file_path = root + file\n",
    "                # file_path= \"/Volumes/MyPassport1/D1/depth/5724PM/_Depth_7639.png\"\n",
    "                if file_path == \"/Volumes/MyPassport1/D1/depth/4973AM/.__Depth_1237.png\":\n",
    "                    continue\n",
    "\n",
    "                print(\"Now is running: \", file_path)\n",
    "                \n",
    "                # Build na of summary file.\n",
    "                frame = os.path.splitext(file)[0]\n",
    "                width = np.nan\n",
    "                length = np.nan\n",
    "                height0 = np.nan \n",
    "                height1 = np.nan \n",
    "                volume = np.nan\n",
    "\n",
    "                # Read in images.\n",
    "                img = io.imread(file_path)\n",
    "\n",
    "                # Read in distance csv files\n",
    "                filename = os.path.splitext(file)[0]+\".csv\"\n",
    "                # print(filename)\n",
    "                csv_path = os.path.join(csvdir, filename)\n",
    "                dfcsv = pd.read_csv(csv_path, header = None) #read in depth csv file\n",
    "\n",
    "                # Using mrcnn to predict contour (result is binary image with size 848*480) \n",
    "                fill_img = predict_mrcnn.predict_mrcnn(img) #bianry image after mrcnn \n",
    "                \n",
    "                #mrcnn can just give us overall mask, but we need the contour, so we have to draw it again.\n",
    "                cnts, _ = cv2.findContours(fill_img.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) \n",
    "                cmax = max(cnts, key=cv2.contourArea) \n",
    "\n",
    "                  ##part1: calculate width and length\n",
    "                rect = cv2.minAreaRect(cmax)\n",
    "                box = cv2.boxPoints(rect)\n",
    "                (A, B, C, D) = np.int0(box)\n",
    "                d0 = dist.euclidean(B, C)\n",
    "                d1 = dist.euclidean(A, B)\n",
    "                width = min(d0, d1)\n",
    "                length = max(d0, d1)\n",
    "\n",
    "                  ##part2: calculated height: centroid method\n",
    "                M = cv2.moments(cmax)\n",
    "                row_centroid = int(M[\"m01\"] / M[\"m00\"])\n",
    "                col_centroid  = int(M[\"m10\"] / M[\"m00\"])\n",
    "                height0 = 2.94 - dfcsv.iloc[row_centroid , col_centroid]\n",
    "\n",
    "                  ##part3: calculate height: average method\n",
    "                pixel = np.argwhere(fill_img == 255) #find pixels for white part\n",
    "                dfcsv_rows = [] #combine pixel and distance \n",
    "                for row, col in pixel:\n",
    "                  dfcsv_rows.append([row, col, dfcsv.iloc[row, col]])\n",
    "                df = pd.DataFrame(dfcsv_rows, columns = ['row', 'col', 'dist'])\n",
    "\n",
    "                df.dist.replace(to_replace=0, value = df.dist.mean(), inplace=True) #replace 0 with average distance\n",
    "                height1 = 2.94 - df.dist.mean()\n",
    "\n",
    "                  ##part4: calculate volume\n",
    "                df[\"height\"] = 2.94 - df[\"dist\"] #build new column named height\n",
    "                volume = sum(df.height)\n",
    "\n",
    "                  ##part5: write into csv file.\n",
    "                frame = os.path.splitext(file)[0]\n",
    "                writer.writerow([Day, ID, frame, width, length, height0, height1, volume])\n",
    "                i = i + 1\n",
    "                print(\"####################### Done %d ############################\" %i)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a8443bcda671d1b6ebaa7d5cd00129e36ed697745ce7e03c7bff49918dbef1cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
